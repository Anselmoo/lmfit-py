
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "examples/example_emcee_Model_interface.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_examples_example_emcee_Model_interface.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_examples_example_emcee_Model_interface.py:


Emcee and the Model Interface
=============================

.. GENERATED FROM PYTHON SOURCE LINES 6-13

.. code-block:: default

    import corner
    import matplotlib.pyplot as plt
    import numpy as np

    import lmfit









.. GENERATED FROM PYTHON SOURCE LINES 14-15

Set up a double-exponential function and create a Model

.. GENERATED FROM PYTHON SOURCE LINES 15-21

.. code-block:: default

    def double_exp(x, a1, t1, a2, t2):
        return a1*np.exp(-x/t1) + a2*np.exp(-(x-0.1) / t2)


    model = lmfit.Model(double_exp)








.. GENERATED FROM PYTHON SOURCE LINES 22-23

Generate some fake data from the model with added noise

.. GENERATED FROM PYTHON SOURCE LINES 23-28

.. code-block:: default

    truths = (3.0, 2.0, -5.0, 10.0)
    x = np.linspace(1, 10, 250)
    np.random.seed(0)
    y = double_exp(x, *truths)+0.1*np.random.randn(x.size)








.. GENERATED FROM PYTHON SOURCE LINES 29-30

Create model parameters and give them initial values

.. GENERATED FROM PYTHON SOURCE LINES 30-32

.. code-block:: default

    p = model.make_params(a1=4, t1=3, a2=4, t2=3)








.. GENERATED FROM PYTHON SOURCE LINES 33-34

Fit the model using a traditional minimizer, and show the output:

.. GENERATED FROM PYTHON SOURCE LINES 34-39

.. code-block:: default

    result = model.fit(data=y, params=p, x=x, method='Nelder', nan_policy='omit')

    lmfit.report_fit(result)
    result.plot()




.. image:: /examples/images/sphx_glr_example_emcee_Model_interface_001.png
    :alt: Model(double_exp)
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    /home/matt/Codes/lmfit-py/examples/example_emcee_Model_interface.py:16: RuntimeWarning: overflow encountered in exp
      return a1*np.exp(-x/t1) + a2*np.exp(-(x-0.1) / t2)
    /home/matt/Codes/lmfit-py/examples/example_emcee_Model_interface.py:16: RuntimeWarning: overflow encountered in multiply
      return a1*np.exp(-x/t1) + a2*np.exp(-(x-0.1) / t2)
    /home/matt/anaconda3/lib/python3.8/site-packages/lmfit-1.0.1+182.gddf7d40-py3.8.egg/lmfit/minimizer.py:184: RuntimeWarning: overflow encountered in multiply
      return (r*r).sum()
    [[Fit Statistics]]
        # fitting method   = Nelder-Mead
        # function evals   = 609
        # data points      = 250
        # variables        = 4
        chi-square         = 2.33333982
        reduced chi-square = 0.00948512
        Akaike info crit   = -1160.54007
        Bayesian info crit = -1146.45423
    [[Variables]]
        a1:  2.98623689 +/- 0.15010519 (5.03%) (init = 4)
        t1:  1.30993186 +/- 0.13449653 (10.27%) (init = 3)
        a2: -4.33525597 +/- 0.11765821 (2.71%) (init = 4)
        t2:  11.8240752 +/- 0.47172598 (3.99%) (init = 3)
    [[Correlations]] (unreported correlations are < 0.100)
        C(a2, t2) =  0.988
        C(t1, a2) = -0.928
        C(t1, t2) = -0.885
        C(a1, t1) = -0.609
        C(a1, a2) =  0.297
        C(a1, t2) =  0.232

    (<Figure size 640x640 with 2 Axes>, GridSpec(2, 1, height_ratios=[1, 4]))



.. GENERATED FROM PYTHON SOURCE LINES 40-46

Calculate parameter covariance using emcee:

 - start the walkers out at the best-fit values
 - set is_weighted to False to estimate the noise weights
 - set some sensible priors on the uncertainty to keep the MCMC in check


.. GENERATED FROM PYTHON SOURCE LINES 46-51

.. code-block:: default

    emcee_kws = dict(steps=1000, burn=300, thin=20, is_weighted=False,
                     progress=False)
    emcee_params = result.params.copy()
    emcee_params.add('__lnsigma', value=np.log(0.1), min=np.log(0.001), max=np.log(2.0))








.. GENERATED FROM PYTHON SOURCE LINES 52-53

run the MCMC algorithm and show the results:

.. GENERATED FROM PYTHON SOURCE LINES 53-62

.. code-block:: default

    result_emcee = model.fit(data=y, x=x, params=emcee_params, method='emcee',
                             nan_policy='omit', fit_kws=emcee_kws)

    lmfit.report_fit(result_emcee)

    ax = plt.plot(x, model.eval(params=result.params, x=x), label='Nelder', zorder=100)
    result_emcee.plot_fit(ax=ax, data_kws=dict(color='gray', markersize=2))
    plt.show()




.. image:: /examples/images/sphx_glr_example_emcee_Model_interface_002.png
    :alt: Model(double_exp)
    :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none

    The chain is shorter than 50 times the integrated autocorrelation time for 5 parameter(s). Use this estimate with caution and run a longer chain!
    N/50 = 20;
    tau: [42.15512406 49.13844172 47.97313337 48.69759859 39.90675732]
    [[Fit Statistics]]
        # fitting method   = emcee
        # function evals   = 100000
        # data points      = 250
        # variables        = 5
        chi-square         = 245.611753
        reduced chi-square = 1.00249695
        Akaike info crit   = 5.57278242
        Bayesian info crit = 23.1800870
    [[Variables]]
        a1:         2.99014520 +/- 0.15080185 (5.04%) (init = 2.986237)
        t1:         1.32465508 +/- 0.14246577 (10.75%) (init = 1.309932)
        a2:        -4.34626582 +/- 0.12518881 (2.88%) (init = -4.335256)
        t2:         11.7839459 +/- 0.48230303 (4.09%) (init = 11.82408)
        __lnsigma: -2.32797933 +/- 0.04489245 (1.93%) (init = -2.302585)
    [[Correlations]] (unreported correlations are < 0.100)
        C(a2, t2) =  0.981
        C(t1, a2) = -0.939
        C(t1, t2) = -0.898
        C(a1, t1) = -0.540
        C(a1, a2) =  0.257
        C(a1, t2) =  0.225




.. GENERATED FROM PYTHON SOURCE LINES 63-64

check the acceptance fraction to see whether emcee performed well

.. GENERATED FROM PYTHON SOURCE LINES 64-69

.. code-block:: default

    plt.plot(result_emcee.acceptance_fraction)
    plt.xlabel('walker')
    plt.ylabel('acceptance fraction')
    plt.show()




.. image:: /examples/images/sphx_glr_example_emcee_Model_interface_003.png
    :alt: example emcee Model interface
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 70-71

try to compute the autocorrelation time

.. GENERATED FROM PYTHON SOURCE LINES 71-78

.. code-block:: default

    if hasattr(result_emcee, "acor"):
        print("Autocorrelation time for the parameters:")
        print("----------------------------------------")
        for i, p in enumerate(result.params):
            print(p, result.acor[i])









.. GENERATED FROM PYTHON SOURCE LINES 79-80

Plot the parameter covariances returned by emcee using corner

.. GENERATED FROM PYTHON SOURCE LINES 80-83

.. code-block:: default

    emcee_corner = corner.corner(result_emcee.flatchain, labels=result_emcee.var_names,
                                 truths=list(result_emcee.params.valuesdict().values()))




.. image:: /examples/images/sphx_glr_example_emcee_Model_interface_004.png
    :alt: example emcee Model interface
    :class: sphx-glr-single-img





.. GENERATED FROM PYTHON SOURCE LINES 85-101

.. code-block:: default

    print("\nmedian of posterior probability distribution")
    print('--------------------------------------------')
    lmfit.report_fit(result_emcee.params)

    # find the maximum likelihood solution
    highest_prob = np.argmax(result_emcee.lnprob)
    hp_loc = np.unravel_index(highest_prob, result_emcee.lnprob.shape)
    mle_soln = result_emcee.chain[hp_loc]
    print("\nMaximum likelihood Estimation")
    print('-----------------------------')
    for ix, param in enumerate(emcee_params):
        print(param + ': ' + str(mle_soln[ix]))

    quantiles = np.percentile(result_emcee.flatchain['t1'], [2.28, 15.9, 50, 84.2, 97.7])
    print("\n\n1 sigma spread", 0.5 * (quantiles[3] - quantiles[1]))
    print("2 sigma spread", 0.5 * (quantiles[4] - quantiles[0]))




.. rst-class:: sphx-glr-script-out

 Out:

 .. code-block:: none


    median of posterior probability distribution
    --------------------------------------------
    [[Variables]]
        a1:         2.99014520 +/- 0.15080185 (5.04%) (init = 2.986237)
        t1:         1.32465508 +/- 0.14246577 (10.75%) (init = 1.309932)
        a2:        -4.34626582 +/- 0.12518881 (2.88%) (init = -4.335256)
        t2:         11.7839459 +/- 0.48230303 (4.09%) (init = 11.82408)
        __lnsigma: -2.32797933 +/- 0.04489245 (1.93%) (init = -2.302585)
    [[Correlations]] (unreported correlations are < 0.100)
        C(a2, t2) =  0.981
        C(t1, a2) = -0.939
        C(t1, t2) = -0.898
        C(a1, t1) = -0.540
        C(a1, a2) =  0.257
        C(a1, t2) =  0.225

    Maximum likelihood Estimation
    -----------------------------
    a1: 2.9704980735108304
    t1: 1.3209758260802968
    a2: -4.338098241979906
    t2: 11.838963811736026
    __lnsigma: -2.3403986558500596


    1 sigma spread 0.14233438845386803
    2 sigma spread 0.2943016210688928





.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  7.231 seconds)


.. _sphx_glr_download_examples_example_emcee_Model_interface.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: example_emcee_Model_interface.py <example_emcee_Model_interface.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: example_emcee_Model_interface.ipynb <example_emcee_Model_interface.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
